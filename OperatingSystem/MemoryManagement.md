# Memory Management
## Background
* Main memory and registers are the only storage CPU can access directly
* Collection of processes are waiting on disk to be `brought into memory and be executed`
* `Multiple programs are brought into memory` to improve resource utilization and response time to users
* A process may be `moved between disk and memory` during its execution(e.g. virtual memory)

### How to refer memory in a program: Address Binding

* Address Binding - Compile Time
	* Program is written as symbolic code
	* Compiler translates symbolic code into `absolute code`
	* If starting location changes -> recompile

* Address Binding - Load Time
	* Compiler translates symbolic code into `relocatable code`
	* Relocatable code: Machine language that can be run from any memory location
	* If starting location changes -> reload the code

* Address Binding - Execution Time(Runtime)
	* Compiler translates symbolic code into logical-address(i.e. virtual-address) code
	* Special hardware(i.e. MMU) is needed for this scheme
	* Most general-purpose OS use this method

* Memory-Management Unit(MMU)
	* Hardware device that maps virtual to physical address
	* The value in the `relocation register is added to every address` generated by a user process at the time it is sent to memory

* Logical v.s. Physical Address
	* Logical address(a.k.a virtual address) - generated by CPU
	* Physical address - seen by the memory module
	* Compile-time & load-time address binding(logical address = physical address)
	* Execution-time address binding(logical address != physical address)
	* The user program deals with logical addresses; it never sees the real physical addresses

### How to load a program into memory: static/dynamic loading and linking

#### Dynamic loading
* Does the entire program must be in the memory for it to execute? No, we can use dynamic-loading
	* A routine(function call) is loaded into memory when it is called
* `Better memory-space utilization`
	* unused routine is never loaded
	* Particularly useful when large amounts of code are infrequently used(e.g. error handling code)
* `No special support from OS` is required implemented through program(library, API calls)

#### Static Linking
* linking: function call the code from libraries
* Static linking: libraries are combined by the loader into the program in-memory image
	* Waste memory: duplicated code
	* Faster during execution time
	* Static linking + Dynamic loading still can not prevent duplicated code

#### Dynamic Linking
* Dynamic linking: Linking postponed `until execution time`
	* `Only one code copy` in memory and `shared by everyone`
	* A stub is included in the program in-memory image for each lib reference
	* Stub call -> check if the referred lib is in memory -> in not, load the lib -> execute the lib
	* e.g. DDL(Dynamic link library) on Windows

## `Swapping`
* How to move a program between mem. & disk: swap
* Swapping: A process can be swapped out of memory to `backing store`, and later brought back into memory for contiguous execution
	* Also used by `midterm scheduling`, different from context switch
* `Backing store` - a chunk of disk, separated from file system, to provide direct access to these memory images
* Why swap a process
	* Free up memory
	* Roll out, roll in: swap lower priority process with a higher one

* Swap back memory location
	* If binding is done at compile/load time: swap back memory address must be the same
	* If binding is done at execution time: swap back memory address can be different

* A process to be swapped == `must be idle`
	* Solutions for preventing from swapping the process that is waiting for I/O:
 		* Never swap a process with pending I/O
 		* Or I/O operations are done through OS buffers(i.e. a memory space not belongs to any user processes)

* Process Swapping to Backing Store
	* Major part of swap time is transfer time; `total transfer time is directly proportional to the amount of memory swapped`

## Contiguous Memory Allocation

### Memory Allocation
* Fixed-partition allocation
	* Each process loads into one partition of fixed-size
	* `Degree of muli-programming` is bounded by the number of partitions

* Variable-size partition
	* Hole: block of contiguous free memory
	* Holes of various size are scattered in memory

* Multiple Partition(Variable-Size) Method
	* When a process arrives, it is allocated a hole large enough to accommodate it
	* The OS maintains info. on each `in-use` and `free-hole`
	* A free hole can be merged with another hole to form a larger hole

* Dynamic Storage Allocation Problem
	* How to satisfy a request of size n from a list of free holes
	* `First-fit` - allocate the 1st hole that fits
	* `Best-fit` - allocate the smallest hole that fits: Must search through the whole list
	* `Worst-fit` - allocate the largest hole: Must also search through the whole list
	* First-fit and best-fit better than worst-fit in terms of speed and storage utilization

### Fragmentation
* External fragmentation
	* Total free memory space is big enough to satisfy a request, but is not contiguous
	* `Occur in variable-size allocation`
* Internal fragmentation
	* Memory that is internal to a partition but is not being used
	* `Occur in fixed-partition allocation`

* Solution: `compactiion`
	* Shuffle the memory contents to place all free memory together in one large block `at execution time`
	* Only if binding is done at execution time

## Non-Contiguous Memory Allocation - Paging
* Paging Concept
	* Methods
		* `Frames`: Divide physical memory into fixed-sized blocks
		* `Pages`: Divide logical address space into blocks of the `same size`
		* To run a program of n pages, need to find n free frames and load the program
		* `keep track of free frames`
		* Step up a `page table` to translate logical to physical addresses

	* Benefit
		* Allow the physical-address space of the process to be `noncontiguous`
		* Avoid external fragmentation
		* Limited internal fragmentation(factor: size of a page)
		* Provide `shared memory/pages`

* Page table
	* Each entry maps to the `base address of a page` in physical memory
	* A structure maintained by OS `for each process`
		* Page table includes only pages owned by a process
		* A process cannot access memory outside its space

### Address Translation Scheme
* Logical address is divided into two parts
	* `Page number(p)`
		* used as an index into a page table which contains base address of each page in physical memory
		* N bits means a process can allocate `at most (2 raised to the power of N) pages` -> (2 raised to the power of N) multiply page size memory size

	* `Page offset(d)`
		* combined with base address to define the physical memory address that is sent to the memory unit
		* N bits means the page size is `2 raised to the power of N`

* Physical address = page base address + page offset

### Address Translation
* Total number of pages does not need to be the same as the total number of frames
	* Total # pages determines the logical memory size of a process
	* Total # frames depending on the size of physical memory

* OS maintains a `frame table` for managing physical memory
	* One entry for each physical frame
	* Indicate whether a frame is free or allocated
	* If allocated, to which page of which process or processes
* Free frame list maintained by OS

* Page/Frame Size
	* The page(frame) size is defined by hardware
		* Typically a power of 2
		* Ranging from 512 bytes to 6MB/page
		* 4kB/8Kb page is commonly used

	* Internal fragmentation?
		* Large page size -> More space waste
	* But `page size have grown over time`
		* memory, process, data sets have become larger
		* better I/O performance(during page fault)
		* `page table is smaller`

### Implementation of Page Table
* Page table is kept `in memory`
* `Page-table base register(PTBR)
	* The `physical memory address` of the page table
	* The PTBR value is stored in PCB(Process Control Block)
 	* Changing the value of PTBR during Context-switch

* With PTBR, each memory reference result in `2 memory reads`
	* One for the page table and one for the real address
* The 2-access problem can be solved by
	* `Translation Look-aside Buffer(TLB)` (HW) which is implemented by `Associative memory`(HW)

* Associative Memory
	* All memory entries can be accessed at the same time
		* Each entry corresponds to an associative register
	* But number of entries are limited
		* Typical number of entries: 64~1024
	* Associative memory - parallel search
		* Address translation (A', A'')
			* If A' is in associative register, hey frame # out. (lookup time O(1))
			* Otherwise get frame # from page table in memory

* Translation Look-aside Buffer(TLB)
	* `A cache for page table shared by all processes`
	* TLB must be flushed after a context switch
		* Otherwise, TLB entry must has a PID field(address-space identifiers(ASIDs))

* Effective Memory-Access Time
	* 20ns for TLB search
	* 100ns for memory access
	* Effective Memory-Access Time(EMAT)
		* 70% TLB hit-ratio: EMAT = 0.7 * (20 + 100) + (1-0.7) * (20 + 100 + 100) = 150ns
		* 98% TLB hit-ratio: EMAT = 0.98 * (20 + 100) + (1-0.98) * (20 + 100 + 100) = 122ns

### Memory Protection
* Each page is associated with a set of protection bit in the page table
	* a bit to define read/write/execution permission
* Common use: valid-invalid bit
	* Valid: the page/frame is in the process' logical space, and is thus a legal page
	* Invalid: the page/frame is not in the process' logical address space
* Potential Issues:
	Unused page entry cause memory waste -> use page table length register(PTLR)
	* Process memory may NOT be on the boundary of a page -> memory limit register is still needed

### Shared Pages
* Paging allows processes share common code, which must be reentrant
* Reentrant code(pure code)
	* It never change during execution
	* text editors, compilers, web servers, etc
* Only one copy of the shared code needs to be kept in physical memory
* Two(several) virtual addresses are mapped to one physical address
* Process keeps a copy of its own private data and code

* Shared Pages by Page Table
	* Shared code must appear in the same location in the logical address space of all processes

### Page Table Memory Structure
* Page table could be huge and difficult to be loaded
	* `Need to break it into several smaller page tables, better within a single page size(i.e. 4KB)`
	* `Or reduce the total size of page table`
* Solutions
	* Hierarchical Paging
	* Hash Page Tables
	* Inverted Page Table

## Non-Contiguous Memory Allocation - Segmentation
### Segmentation
* Memory-management that supports user view of memory
* A program is a collection of segments. A segment is a logical unit such as:
	* main program
	* function, object
	* local/global variables
	* stack, symbol table,
	* arrays, etc...

### Segmentation Table
* Logical address: (seg#, offset)
	* Offset has the SAME length as physical address
* Segmentation Table - maps two-dimensional physical addresses; each table entry has:
	* `Base(4 bytes)`: the start physical address
	* `Limit(4 bytes)`: the length of the segment. (To check if the offset is valid or not)
* Segment-table base register (STBR)
	* the physical address of the segmentation table
* Segment-table length register (STLR)
	* the number of segments

### Segmentation Hardware
* Limit register is used to check offset length
* MMU allocate memory by assigning an appropriate `base address for each segment`
	* physical address cannot overlap between segments

### Address Translation Comparison
* Segment
	* Table entry: (segment base address, limit)
	* Segment base address can be 
	* The length of "offset" is the same as the physical memory size

* Page
	* Table entry: (frame base address)
	* Frame base address = frame number * page size
	* The length of "offset" is the same as page size

### Protection & Sharing
* Protection bits associated with segments
	* Read-only segment(code)
	* Read-write segment(data, heap stack)
* Code sharing occurs at `segment level`
	* `Shared memory communication`
	* `Shared library`
* Share segment by having same base in two segment tables

## Segmentation with Paging
* Basic Concept
	* Apply `segmentation` in `logical` address space
	* Apply `paging` in `physical` address space
	* Paging after segmentation

### Address Translation
* CPU generates logical address
	* Given to `segmentation unit` -> produces `linear addresses`
	* Linear address given to `paging unit` -> generates `physical address` in main memory
* Segmentation and paging units form equivalent of MMU
[CPU] -logical address-> [segmentation unit] - linear address-> [paging unit] -physical address->[physical memory]

# References
* [Operating System Course by Jerry Chou](https://www.youtube.com/playlist?list=PLS0SUwlYe8czigQPzgJTH2rJtwm0LXvDX)